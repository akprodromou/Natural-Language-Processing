{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kAxBQlDGhjubTD3YGCW_O0sXpQt_KlBu","timestamp":1760985748147}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"YTonIZGyA5TE","executionInfo":{"status":"ok","timestamp":1761022953472,"user_tz":-180,"elapsed":13,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}}},"outputs":[],"source":["import re\n","text = '''Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n","\n","The history of natural language processing (NLP) generally started in the 1950s, although work can be found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence.\n","\n","oh! ooh! oooh! ooooh!\n","\n","US: My favorite color is blue\n","\n","UK: My favourite colour is red\n","\n","begin began begun beg3n\n","\n","puppy, puppies\n","\n","column 1 column 2 column 12\n","\n","The happier they were, the happier they will be\n","The happier they were, the richer they will be\n","The richer they were, the richer they will be'''"]},{"cell_type":"markdown","source":["Finds all matches"],"metadata":{"id":"LEf653xZVu2d"}},{"cell_type":"code","source":["re.findall('natural', text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Px2OBnGB3aY-","executionInfo":{"status":"ok","timestamp":1761022956128,"user_tz":-180,"elapsed":10,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"4688249a-e7ec-4b5f-8db9-8c2eecc5fddc"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['natural', 'natural', 'natural']"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["Replaces all matches"],"metadata":{"id":"sbcHTnAnVx6a"}},{"cell_type":"code","source":["re.sub('engineering', 'processing', 'natural language engineering')\n","re.sub('Natural', \"Habitual\", \"Natural Habitat\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"gq3VVr-v4JsQ","executionInfo":{"status":"ok","timestamp":1761022985591,"user_tz":-180,"elapsed":54,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"eeb25ce4-a0e8-4d2a-a7a5-91e554ed2b4b"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Habitual Habitat'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Checks for a match at the start of the string. Upon a match, it returns a match object containing span and actual match."],"metadata":{"id":"Gz2oamLMV-F6"}},{"cell_type":"code","source":["re.match('Natur', text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixZqQKaEVJty","executionInfo":{"status":"ok","timestamp":1759846549561,"user_tz":-180,"elapsed":37,"user":{"displayName":"Grigorios Tsoumakas","userId":"13048321804834071528"}},"outputId":"79b314dc-2f9b-4f77-e9e7-e678155fe089"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<re.Match object; span=(0, 5), match='Natur'>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Return an iterator over all non-overlapping matches in the string."],"metadata":{"id":"OEbukiilWGOF"}},{"cell_type":"code","source":["matches = re.finditer('[Nn]atural', text)\n","for match in matches:\n","    print(match)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wokj26XlB5Bl","executionInfo":{"status":"ok","timestamp":1759846549561,"user_tz":-180,"elapsed":23,"user":{"displayName":"Grigorios Tsoumakas","userId":"13048321804834071528"}},"outputId":"4ba09506-2dfa-4564-ad8f-717014ac898f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<re.Match object; span=(0, 7), match='Natural'>\n","<re.Match object; span=(196, 203), match='natural'>\n","<re.Match object; span=(295, 302), match='natural'>\n","<re.Match object; span=(334, 341), match='natural'>\n"]}]},{"cell_type":"code","source":["# Exclude uppercase, lowercase, dollar sign, caret, parenthesis, comma, period, exlamation mark, digits, colon, double quotes\n","matches = re.finditer('[^A-Z$^a-z )(,).!0-9:\"]', text)\n","for match in matches:\n","    print(match)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCGLhcKc3N8l","executionInfo":{"status":"ok","timestamp":1759846549561,"user_tz":-180,"elapsed":9,"user":{"displayName":"Grigorios Tsoumakas","userId":"13048321804834071528"}},"outputId":"84fe5631-f18c-4045-bf48-250200306431"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<re.Match object; span=(317, 318), match='\\n'>\n","<re.Match object; span=(318, 319), match='\\n'>\n","<re.Match object; span=(618, 619), match='\\n'>\n","<re.Match object; span=(619, 620), match='\\n'>\n","<re.Match object; span=(641, 642), match='\\n'>\n","<re.Match object; span=(642, 643), match='\\n'>\n","<re.Match object; span=(672, 673), match='\\n'>\n","<re.Match object; span=(673, 674), match='\\n'>\n","<re.Match object; span=(704, 705), match='\\n'>\n","<re.Match object; span=(705, 706), match='\\n'>\n","<re.Match object; span=(729, 730), match='\\n'>\n","<re.Match object; span=(730, 731), match='\\n'>\n","<re.Match object; span=(745, 746), match='\\n'>\n","<re.Match object; span=(746, 747), match='\\n'>\n","<re.Match object; span=(774, 775), match='\\n'>\n","<re.Match object; span=(775, 776), match='\\n'>\n","<re.Match object; span=(823, 824), match='\\n'>\n","<re.Match object; span=(870, 871), match='\\n'>\n"]}]},{"cell_type":"code","source":["# Match any single character between N^LP\n","matches = re.finditer('[N^LP]', text)\n","for match in matches:\n","    print(match)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XWSKq3jf5mIa","executionInfo":{"status":"ok","timestamp":1759846549570,"user_tz":-180,"elapsed":12,"user":{"displayName":"Grigorios Tsoumakas","userId":"13048321804834071528"}},"outputId":"e0fcddba-9924-45da-dcb4-56b2e64a621f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<re.Match object; span=(0, 1), match='N'>\n","<re.Match object; span=(29, 30), match='N'>\n","<re.Match object; span=(30, 31), match='L'>\n","<re.Match object; span=(31, 32), match='P'>\n","<re.Match object; span=(363, 364), match='N'>\n","<re.Match object; span=(364, 365), match='L'>\n","<re.Match object; span=(365, 366), match='P'>\n"]}]},{"cell_type":"markdown","source":["Disjunction with pipe\n","*   [Nn]atural language processing|NLP\n","*   a|b|c which is equivalent to [abc]\n","*   [A-Z]|[0-9]"],"metadata":{"id":"sZh0bBUz6A22"}},{"cell_type":"code","source":["matches = re.finditer('[Nn]atural language processing|NLP', text)\n","for match in matches:\n","    print(match)"],"metadata":{"id":"95nCz1sJIJEe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759846549571,"user_tz":-180,"elapsed":6,"user":{"displayName":"Grigorios Tsoumakas","userId":"13048321804834071528"}},"outputId":"bd27e0c0-d14e-46e2-8ba7-5d735ee6e648"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<re.Match object; span=(0, 27), match='Natural language processing'>\n","<re.Match object; span=(29, 32), match='NLP'>\n","<re.Match object; span=(334, 361), match='natural language processing'>\n","<re.Match object; span=(363, 366), match='NLP'>\n"]}]},{"cell_type":"markdown","source":["# Counters and company"],"metadata":{"id":"zT_qzl0k6aeQ"}},{"cell_type":"markdown","source":["\\* for zero or more previous characters\n","*   ll*\n","*   oo*h!"],"metadata":{"id":"taEphOdy6hTl"}},{"cell_type":"code","source":["matches = re.finditer('o+h!', text)\n","for match in matches:\n","    print(match)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMwkXArQB0CS","executionInfo":{"status":"ok","timestamp":1759846549581,"user_tz":-180,"elapsed":9,"user":{"displayName":"Grigorios Tsoumakas","userId":"13048321804834071528"}},"outputId":"9539c47b-7d3f-4427-e782-411ab5cac2de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<re.Match object; span=(620, 623), match='oh!'>\n","<re.Match object; span=(624, 628), match='ooh!'>\n","<re.Match object; span=(629, 634), match='oooh!'>\n","<re.Match object; span=(635, 641), match='ooooh!'>\n"]}]}]}