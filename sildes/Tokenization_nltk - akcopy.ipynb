{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"provenance":[{"file_id":"1n2wHe6iP8O-zT_vdmi1-YNlHg3aWgVKE","timestamp":1760951660806}],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"CgoAPsxiJ1TB"},"source":["# Corpora"]},{"cell_type":"code","metadata":{"id":"CYm1LeMdJ1TG","executionInfo":{"status":"ok","timestamp":1760953650727,"user_tz":-180,"elapsed":4,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}}},"source":["import nltk"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"whfncBxQKeCj"},"source":["If you are working locally you could download parts or the whole of NLTK, including corpora, with the following code"]},{"cell_type":"code","metadata":{"id":"gDSwNi_tJ1TP","executionInfo":{"status":"ok","timestamp":1760953650738,"user_tz":-180,"elapsed":1,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}}},"source":["#nltk.download()"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvnP_Ps_J1TV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953650756,"user_tz":-180,"elapsed":16,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"b5543255-eea8-45bb-e76b-6623d412108d"},"source":["nltk.download('gutenberg')\n","from nltk.corpus import gutenberg"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"Xlnh5rH_K507"},"source":["The function `fileids()` returns a list of the files in a corpus"]},{"cell_type":"code","metadata":{"id":"7mlwdf9eJ1Tc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953650794,"user_tz":-180,"elapsed":36,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"1b4aab60-b0fb-4b40-b9ac-967d7a4b3400"},"source":["gutenberg.fileids()"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['austen-emma.txt',\n"," 'austen-persuasion.txt',\n"," 'austen-sense.txt',\n"," 'bible-kjv.txt',\n"," 'blake-poems.txt',\n"," 'bryant-stories.txt',\n"," 'burgess-busterbrown.txt',\n"," 'carroll-alice.txt',\n"," 'chesterton-ball.txt',\n"," 'chesterton-brown.txt',\n"," 'chesterton-thursday.txt',\n"," 'edgeworth-parents.txt',\n"," 'melville-moby_dick.txt',\n"," 'milton-paradise.txt',\n"," 'shakespeare-caesar.txt',\n"," 'shakespeare-hamlet.txt',\n"," 'shakespeare-macbeth.txt',\n"," 'whitman-leaves.txt']"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"yyXQ51DzJ1TZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953650802,"user_tz":-180,"elapsed":11,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"385d0432-3520-4b8d-c0d2-b79ff4002e61"},"source":["len(gutenberg.fileids())"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"yGvceonjLHH4"},"source":["The function `sents` returns the sentences of a file as a list. Each sentence is representend as an inner list of the obtained tokens after tokenization with the [Punkt](https://www.nltk.org/_modules/nltk/tokenize/punkt.html) tokenizer. We will use it to obtain the sentences from Jane Austen's \"Emma\". See also the [source](https://www.gutenberg.org/ebooks/158) of the book.   "]},{"cell_type":"code","metadata":{"id":"bDTdE9ILJ1Tf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953651990,"user_tz":-180,"elapsed":1189,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"918846a9-8450-4dea-cd9d-80f177cf009e"},"source":["nltk.download('punkt_tab')\n","sents = gutenberg.sents('bible-kjv.txt')\n","print(len(sents))\n","print(sents)\n","print(sents[3])"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["30103\n","[['[', 'The', 'King', 'James', 'Bible', ']'], ['The', 'Old', 'Testament', 'of', 'the', 'King', 'James', 'Bible'], ...]\n","['1', ':', '1', 'In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"shf3LUeWNcFF"},"source":["The function `words` returns the words of a file as a list. We will use it to obtain the words from Jane Austen's \"Emma\"."]},{"cell_type":"code","metadata":{"id":"46H_U9s6J1Tk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953652712,"user_tz":-180,"elapsed":721,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"9b1a2cfb-f722-4f1e-b145-95775f99382d"},"source":["words = gutenberg.words('bible-kjv.txt')\n","print(len(words))\n","print(words)\n","print(words[11:20])"],"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["1010654\n","['[', 'The', 'King', 'James', 'Bible', ']', 'The', ...]\n","['King', 'James', 'Bible', 'The', 'First', 'Book', 'of', 'Moses', ':']\n"]}]},{"cell_type":"markdown","metadata":{"id":"K4iFrapjOsWl"},"source":["The function `raw` returns the raw text of a file as a list. We will use it to obtain the raw text from Jane Austen's \"Emma\"."]},{"cell_type":"code","metadata":{"id":"gR5XwyXBJ1Tp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953652729,"user_tz":-180,"elapsed":14,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"fbc7cf3b-d318-439c-fd42-6f9b59300433"},"source":["# raw gets the number of characters\n","raw = gutenberg.raw('bible-kjv.txt')\n","print(len(raw))\n","print(raw[1:200])"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["4332554\n","The King James Bible]\n","\n","The Old Testament of the King James Bible\n","\n","The First Book of Moses:  Called Genesis\n","\n","\n","1:1 In the beginning God created the heaven and the earth.\n","\n","1:2 And the earth was without \n"]}]},{"cell_type":"markdown","metadata":{"id":"iXjuH_RHO4JH"},"source":["What is the average length of sentences in number of tokens, and of tokens in number of characters, in \"Emma\"?"]},{"cell_type":"code","metadata":{"id":"HNFlE1UKPA7x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953652750,"user_tz":-180,"elapsed":19,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"0734dcdc-8d7f-457a-98db-9fc4a99cb1d5"},"source":["# That is assuming that tokens are defined as words\n","sent_length = len(words)/len(sents)\n","print(\"Average number of tokens in sentences %.2f\" %(sent_length))\n","word_length = len(raw)/len(words)\n","print(\"Average number of characters in tokens %.2f\" %(word_length))"],"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Average number of tokens in sentences 33.57\n","Average number of characters in tokens 4.29\n"]}]},{"cell_type":"markdown","metadata":{"id":"_uN-JePo8EIz"},"source":["Relationship between types and instances"]},{"cell_type":"code","metadata":{"id":"mYq_wbLB8LCZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953655172,"user_tz":-180,"elapsed":2413,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"83708e99-b353-4a17-b74e-29768ccf371b"},"source":["import math\n","# %d (of integer) is to replace an integer\n","print(\"instances (n for total length): %d\" %(len(words)))\n","# The set() function in Python is used to create a set, which is an unordered collection of unique elements\n","print(\"types (V for distinct words): %d\" %(len(set(words))))\n","print(\"types to instances ratio: %.4f\" %(len(set(words))/len(words)))\n","print(\"square root of instances: %d\" %(math.sqrt(len(words))))\n","print(\"Does K fall between the typical 10 and 100?\")\n","print(\"Assuming b=0.05 => K = V/sqrt(n) = %d\" %(len(set(words)) / math.sqrt(len(words))))"],"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["instances (n for total length): 1010654\n","types (V for distinct words): 13769\n","types to instances ratio: 0.0136\n","square root of instances: 1005\n","Does K fall between the typical 10 and 100?\n","Assuming b=0.05 => K = V/sqrt(n) = 13\n"]}]},{"cell_type":"markdown","metadata":{"id":"-W61ccxFWqjQ"},"source":["# Segmenting words in running text (tokenization)"]},{"cell_type":"markdown","metadata":{"id":"8WX8N2r1U9vT"},"source":["Split text into paragraphs using regular expressions"]},{"cell_type":"code","metadata":{"id":"7RIIR3dVJ1UH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953896017,"user_tz":-180,"elapsed":60,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"1e870705-e694-48c1-fca4-469410a548a8"},"source":["import re\n","# slice the string\n","part = raw[50:1301]\n","print(part)\n","# \"\\n\\n\" matches two consecutive newline characters, which often indicate a paragraph break in text files\n","paragraphs = re.split(\"\\n\\n\", part)\n","print(\"\\nParagraphs\")\n","for paragraph in paragraphs:\n","  print(\"---\")\n","  print(paragraph)\n"],"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["ing James Bible\n","\n","The First Book of Moses:  Called Genesis\n","\n","\n","1:1 In the beginning God created the heaven and the earth.\n","\n","1:2 And the earth was without form, and void; and darkness was upon\n","the face of the deep. And the Spirit of God moved upon the face of the\n","waters.\n","\n","1:3 And God said, Let there be light: and there was light.\n","\n","1:4 And God saw the light, that it was good: and God divided the light\n","from the darkness.\n","\n","1:5 And God called the light Day, and the darkness he called Night.\n","And the evening and the morning were the first day.\n","\n","1:6 And God said, Let there be a firmament in the midst of the waters,\n","and let it divide the waters from the waters.\n","\n","1:7 And God made the firmament, and divided the waters which were\n","under the firmament from the waters which were above the firmament:\n","and it was so.\n","\n","1:8 And God called the firmament Heaven. And the evening and the\n","morning were the second day.\n","\n","1:9 And God said, Let the waters under the heaven be gathered together\n","unto one place, and let the dry land appear: and it was so.\n","\n","1:10 And God called the dry land Earth; and the gathering together of\n","the waters called he Seas: and God saw that it was good.\n","\n","1:11 And God said, Let the earth bring forth grass, the herb yielding\n","seed, and the frui\n","\n","Paragraphs\n","---\n","ing James Bible\n","---\n","The First Book of Moses:  Called Genesis\n","---\n","\n","1:1 In the beginning God created the heaven and the earth.\n","---\n","1:2 And the earth was without form, and void; and darkness was upon\n","the face of the deep. And the Spirit of God moved upon the face of the\n","waters.\n","---\n","1:3 And God said, Let there be light: and there was light.\n","---\n","1:4 And God saw the light, that it was good: and God divided the light\n","from the darkness.\n","---\n","1:5 And God called the light Day, and the darkness he called Night.\n","And the evening and the morning were the first day.\n","---\n","1:6 And God said, Let there be a firmament in the midst of the waters,\n","and let it divide the waters from the waters.\n","---\n","1:7 And God made the firmament, and divided the waters which were\n","under the firmament from the waters which were above the firmament:\n","and it was so.\n","---\n","1:8 And God called the firmament Heaven. And the evening and the\n","morning were the second day.\n","---\n","1:9 And God said, Let the waters under the heaven be gathered together\n","unto one place, and let the dry land appear: and it was so.\n","---\n","1:10 And God called the dry land Earth; and the gathering together of\n","the waters called he Seas: and God saw that it was good.\n","---\n","1:11 And God said, Let the earth bring forth grass, the herb yielding\n","seed, and the frui\n"]}]},{"cell_type":"markdown","metadata":{"id":"GhRdZbbCX_dz"},"source":["Remove line change characters with regular expressions"]},{"cell_type":"code","metadata":{"id":"mUGsMmp4J1Ul","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760953938444,"user_tz":-180,"elapsed":44,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"00a5af69-6436-42af-c351-d81b3b21a322"},"source":["print(paragraphs[2])\n","print(\"---\")\n","print(re.sub(\"\\n\", \" \", paragraphs[2]))"],"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","1:1 In the beginning God created the heaven and the earth.\n","---\n"," 1:1 In the beginning God created the heaven and the earth.\n"]}]},{"cell_type":"markdown","metadata":{"id":"gDCZFQ_KYn82"},"source":["Word tokenization with regular expressions"]},{"cell_type":"code","metadata":{"id":"5BRaM7XpYwTN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760955104578,"user_tz":-180,"elapsed":18,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"29bce8e1-8c9c-4a5e-f9da-a110178ad2e6"},"source":["def word_tokenization_with_regex(text):\n","  \"Split a text string into a list of words.\"\n","  # initiate our counters\n","  words = []\n","  start = 0\n","  # Loops over each character in text - texts are broken into characters\n","  for pos, char in enumerate(text):\n","    # if the word matches any of these\n","    if re.match('[,;. ]', char):\n","      # take the slice up to the previous character\n","      word = text[start: pos]\n","      # and add it to the list\n","      words.append(word)\n","      # increase start by 1 if that character was blank\n","      if char == ' ':\n","        # move the start forward to start grabbing the next word\n","        start = pos + 1\n","      else:\n","        start = pos\n","  # add punctuation as a separate word\n","  if re.match('[,;.]', text[-1]):\n","    words.append(text[-1])\n","  return words\n","\n","print(paragraphs[2])\n","words = word_tokenization_with_regex(paragraphs[2])\n","print(\"---\")\n","for word in words:\n","  print(word)"],"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","1:1 In the beginning God created the heaven and the earth.\n","---\n","\n","1:1\n","In\n","the\n","beginning\n","God\n","created\n","the\n","heaven\n","and\n","the\n","earth\n",".\n"]}]},{"cell_type":"markdown","metadata":{"id":"x34l0OowgdaG"},"source":["Word tokenization with NLTK"]},{"cell_type":"code","metadata":{"id":"85GECS7lJ1VF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760955122611,"user_tz":-180,"elapsed":6,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"27c20401-65bf-4381-992d-8be72062bd82"},"source":["# same as before, using the built-in nltk function\n","from nltk import word_tokenize\n","words = word_tokenize(paragraphs[2])\n","\n","print(paragraphs[2])\n","words = word_tokenize(paragraphs[2])\n","print(\"---\")\n","for word in words:\n","  print(word)"],"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","1:1 In the beginning God created the heaven and the earth.\n","---\n","1:1\n","In\n","the\n","beginning\n","God\n","created\n","the\n","heaven\n","and\n","the\n","earth\n",".\n"]}]},{"cell_type":"markdown","metadata":{"id":"glxZPgZam8Jv"},"source":["Punctuation removal"]},{"cell_type":"code","metadata":{"id":"4IXS-GFWm9Xe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760955170012,"user_tz":-180,"elapsed":18,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"0c517224-57d9-436d-e5d1-4553c5203f7f"},"source":["# 'punctuation' provides a predefined string containing all the characters commonly considered punctuation\n","from string import punctuation\n","print(punctuation)\n","print(\"---\")\n","print(paragraphs[2])\n","print(\"---\")\n","words = word_tokenize(paragraphs[2])\n","print(len(words))\n","print(words)\n","print(\"---\")\n","words_without_punctuation = [word for word in words if word not in punctuation]\n","print(len(words_without_punctuation))\n","print(words_without_punctuation)"],"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","---\n","\n","1:1 In the beginning God created the heaven and the earth.\n","---\n","12\n","['1:1', 'In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.']\n","---\n","11\n","['1:1', 'In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth']\n"]}]},{"cell_type":"markdown","metadata":{"id":"sqWtxQeCgtKg"},"source":["# Normalization (pre LLM era)"]},{"cell_type":"markdown","metadata":{"id":"6JHR4OINisIV"},"source":["Lowercasing is achieved with the `lower` function of strings. It should take place after tokenization, as tokenizers use capitalization as cues to know when to split a paragraph into sentences or a sentence into words"]},{"cell_type":"code","metadata":{"id":"T6DqgfQbiKmn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760951727503,"user_tz":-180,"elapsed":4,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"923dc517-e2ec-4984-de6a-327cd27cf05c"},"source":["print(paragraphs[0])\n","print(\"---\")\n","from nltk import word_tokenize\n","words = word_tokenize(paragraphs[0])\n","words_lower = [word.lower() for word in words]\n","print(words_lower)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n","and happy disposition, seemed to unite some of the best blessings\n","of existence; and had lived nearly twenty-one years in the world\n","with very little to distress or vex her.\n","---\n","['emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"C8tQDgLtkP9A"},"source":["Stemming"]},{"cell_type":"code","metadata":{"id":"wxRQKfmfJ1Vn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760951727517,"user_tz":-180,"elapsed":13,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"54cb293f-a0d8-46bb-f018-9ef1943108a8"},"source":["from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","print(paragraphs[0])\n","print(\"---\")\n","for word in word_tokenize(paragraphs[0]):\n","  stem = ps.stem(word)\n","  if (word != stem):\n","    print(\"%s - %s\" %(word, stem))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n","and happy disposition, seemed to unite some of the best blessings\n","of existence; and had lived nearly twenty-one years in the world\n","with very little to distress or vex her.\n","---\n","Emma - emma\n","Woodhouse - woodhous\n","handsome - handsom\n","comfortable - comfort\n","happy - happi\n","disposition - disposit\n","seemed - seem\n","unite - unit\n","blessings - bless\n","existence - exist\n","lived - live\n","nearly - nearli\n","twenty-one - twenty-on\n","years - year\n","very - veri\n","little - littl\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nZ3LxP8L2bom","executionInfo":{"status":"ok","timestamp":1760951727521,"user_tz":-180,"elapsed":2,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BTSwcFZ3powV"},"source":["Lemmatization. One issue here is that NLTK's lemmatizer also requires the part-of-speech tag of a word to function properly. We will discuss this in a future lecture. By default it considers each word as noun ('n'). Adjectives, adverbs, nouns and verbs are defined by constants 'a', 'r', 'n', 'v' respectively."]},{"cell_type":"code","metadata":{"id":"VBWcnFHcJ1Vy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760951733077,"user_tz":-180,"elapsed":5555,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"8a4feab6-8da0-4f14-eae0-d1d72016d93b"},"source":["nltk.download('omw-1.4')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","wnl = WordNetLemmatizer()\n","print(paragraphs[0])\n","print(\"---\")\n","for word in word_tokenize(paragraphs[0]):\n","  lemma = wnl.lemmatize(word)\n","  if (lemma != word):\n","    print(\"%s - %s\" %(word, lemma))\n","\n","print(wnl.lemmatize(\"lives\"))\n","print(wnl.lemmatize(\"lives\", \"v\"))\n","print(wnl.lemmatize(\"lives\", \"n\"))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n","and happy disposition, seemed to unite some of the best blessings\n","of existence; and had lived nearly twenty-one years in the world\n","with very little to distress or vex her.\n","---\n","blessings - blessing\n","years - year\n","life\n","live\n","life\n"]}]},{"cell_type":"markdown","source":["# Segmenting sentences in running text"],"metadata":{"id":"JdPl2QY0uM57"}},{"cell_type":"markdown","metadata":{"id":"E4hq59PkWJ_u"},"source":["Split paragraph into sentences using regular expressions"]},{"cell_type":"code","metadata":{"id":"fKJ67Q4SJ1Ud","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760951733092,"user_tz":-180,"elapsed":13,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"2929b7b0-597f-4eef-ffa5-de13cbedda9a"},"source":["def sentence_tokenization_with_regex(text):\n","  \"Split a text string into a list of sentences.\"\n","  sentences = []\n","  start = 0\n","  for pos, char in enumerate(text):\n","    if re.match('[!?.]', char):\n","      sentence = text[start: pos+1]\n","      sentences.append(sentence)\n","      start = pos + 1\n","  return sentences\n","\n","print(paragraphs[2])\n","par_sents = sentence_tokenization_with_regex(paragraphs[2])\n","for sent in par_sents:\n","  print(\"---\")\n","  print(sent)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n","less as a governess than a friend, very fond of both daughters,\n","but particularly of Emma.  Between _them_ it was more the intimacy\n","of sisters.  Even before Miss Taylor had ceased to hold the nominal\n","office of governess, the mildness of her temper had hardly allowed\n","her to impose any restraint; and the shadow of authority being\n","now long passed away, they had been living together as friend and\n","friend very mutually attached, and Emma doing just what she liked;\n","highly esteeming Miss Taylor's judgment, but directed chiefly by\n","her own.\n","---\n","Sixteen years had Miss Taylor been in Mr.\n","---\n"," Woodhouse's family,\n","less as a governess than a friend, very fond of both daughters,\n","but particularly of Emma.\n","---\n","  Between _them_ it was more the intimacy\n","of sisters.\n","---\n","  Even before Miss Taylor had ceased to hold the nominal\n","office of governess, the mildness of her temper had hardly allowed\n","her to impose any restraint; and the shadow of authority being\n","now long passed away, they had been living together as friend and\n","friend very mutually attached, and Emma doing just what she liked;\n","highly esteeming Miss Taylor's judgment, but directed chiefly by\n","her own.\n"]}]},{"cell_type":"markdown","metadata":{"id":"cCVE_nsEXcJE"},"source":["Split paragraph into sentences using NLTK"]},{"cell_type":"code","metadata":{"id":"nhMpXc1qXaXT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760951733097,"user_tz":-180,"elapsed":4,"user":{"displayName":"Antonis Prodromou","userId":"17333500148521596256"}},"outputId":"4f6aa4af-9fea-45bb-b27d-0bb624bc2e4a"},"source":["print(paragraphs[2])\n","from nltk import sent_tokenize\n","par_sents = sent_tokenize(paragraphs[2])\n","for par in par_sents:\n","  print(\"---\")\n","  print(par)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n","less as a governess than a friend, very fond of both daughters,\n","but particularly of Emma.  Between _them_ it was more the intimacy\n","of sisters.  Even before Miss Taylor had ceased to hold the nominal\n","office of governess, the mildness of her temper had hardly allowed\n","her to impose any restraint; and the shadow of authority being\n","now long passed away, they had been living together as friend and\n","friend very mutually attached, and Emma doing just what she liked;\n","highly esteeming Miss Taylor's judgment, but directed chiefly by\n","her own.\n","---\n","Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n","less as a governess than a friend, very fond of both daughters,\n","but particularly of Emma.\n","---\n","Between _them_ it was more the intimacy\n","of sisters.\n","---\n","Even before Miss Taylor had ceased to hold the nominal\n","office of governess, the mildness of her temper had hardly allowed\n","her to impose any restraint; and the shadow of authority being\n","now long passed away, they had been living together as friend and\n","friend very mutually attached, and Emma doing just what she liked;\n","highly esteeming Miss Taylor's judgment, but directed chiefly by\n","her own.\n"]}]}]}